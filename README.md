# HR Assistant (Local LLM Chatbot)

## ğŸ“Œ Overview  
This is a **local HR Assistant chatbot** designed to help employees quickly find answers to HR-related questions such as leave policies, benefits, and company information.  

It uses a **Python Flask backend**, an **HTML + JavaScript frontend**, and a **local LLM** (e.g., Ollamaâ€™s Llama3 or Gemma models) for natural language understanding.  

Employees can ask questions like:  
- *â€œHow many sick leaves do I get?â€*  
- *â€œWhat are the paid leave policies?â€*  
- *â€œHow can I apply for a benefit?â€*  

---

## ğŸš€ Key Features  
- **Local AI Assistant** â€“ No external API calls (optional OpenAI API integration available).  
- **HR Policy Storage** â€“ Policies stored in `policies/` folder as text files.  
- **Vector Search** â€“ Uses SentenceTransformers (`all-MiniLM-L6-v2`) + FAISS for efficient policy lookup.  
- **Chat-Style Frontend** â€“ Clean and user-friendly interface.  
- **Supported Queries** â€“ Handles casual leave, paid leave, sick leave, and benefits.  
- **Optional LLM Integration** â€“ Enhances responses using local LLMs (Llama3, Gemma).  

---

## âš ï¸ Limitations  
- Requires sufficient **RAM** to run local LLM models.  
- Answers limited to data inside the `policies/` folder.  
- `vector_store.pkl` (FAISS index) auto-generates on first run if missing.  

---

## ğŸ›  Tools & Libraries  
- Python 3.x  
- Flask  
- SentenceTransformers (`all-MiniLM-L6-v2`)  
- FAISS  
- Ollama (for local LLM)  
- HTML, CSS, JavaScript (frontend)  

---

## ğŸ“‚ Project Structure  

HR-Assistant-Local-LLM/
â”‚
â”œâ”€â”€ app.py # Flask backend
â”œâ”€â”€ .gitignore # Ignore large files
â”œâ”€â”€ vector_store.pkl # FAISS index (generated locally)
â”œâ”€â”€ policies/ # HR policy text files
â”‚ â”œâ”€â”€ leave_policy.txt
â”‚ â””â”€â”€ benefits.txt
â””â”€â”€ static/
â”œâ”€â”€ index.html # Frontend HTML
â””â”€â”€ app.js # JavaScript for chat functionality

yaml
Copy code

---

## âš™ï¸ Setup Instructions  

### 1. Clone the Repository  
```bash
git clone https://github.com/yourusername/HR-Assistant-Local-LLM.git
cd HR-Assistant-Local-LLM
2. Create Virtual Environment
bash
Copy code
python -m venv hrv
source hrv/bin/activate   # Mac/Linux
hrv\Scripts\activate      # Windows
3. Install Dependencies
bash
Copy code
pip install flask sentence-transformers faiss-cpu
4. Install Ollama & Pull LLM Model
Install Ollama â†’ Ollama Docs

Pull a model (example with Llama3):

bash
Copy code
ollama pull llama3
# or
ollama pull gemma:2b
5. Run the Application
bash
Copy code
python app.py
6. Open in Browser
Navigate to â†’ http://127.0.0.1:5000

ğŸ’» Usage
Type HR-related questions in the chatbox.

Chatbot fetches policies from the policies/ folder using vector search.

Local LLM improves natural language answers.

ğŸ“¸ Example Screenshots


ğŸ¤ Contributing
Contributions are welcome! Please fork this repo and submit a pull request.
